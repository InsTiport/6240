{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "\n",
        "!wget http://snap.stanford.edu/jodie/reddit.csv"
      ],
      "metadata": {
        "id": "anif2PGiXaAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "line_count = 0\n",
        "\n",
        "split_id = 0\n",
        "\n",
        "\n",
        "'''\n",
        "Read file\n",
        "'''\n",
        "sample_interactions = []\n",
        "sample_size = math.inf\n",
        "# item_embeddings = defaultdict(list)\n",
        "with open('/content/reddit.csv') as r:\n",
        "    for line in tqdm.tqdm(r.readlines()):\n",
        "        line_count += 1\n",
        "        # exclude header\n",
        "        if line_count > 1:\n",
        "          if line_count <= sample_size:\n",
        "            # get all data attributes\n",
        "            split = line.strip().split(',')\n",
        "            user_id, subreddit_id, timestamp, state_label, features = int(split[0]), int(split[1]), float(split[2]), int(split[3]), ','.join(split[4:])\n",
        "            # print(features.shape)\n",
        "            # item_embeddings[subreddit_id].append(features)\n",
        "            sample_interactions.append([user_id, subreddit_id, state_label, timestamp, features])\n",
        "          else:\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvtVUNg3bzb5",
        "outputId": "b8fa479e-e879-4983-b548-a53ca3036911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 672448/672448 [00:11<00:00, 60381.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "        \n",
        "'''\n",
        "Get Split\n",
        "'''\n",
        "def get_split(data, train_proportion=0.8, seed=0):\n",
        "\n",
        "  size = len(data)\n",
        "\n",
        "  train_size = round(size * train_proportion)\n",
        "  np.random.seed(seed)\n",
        "  train_ids = np.random.choice(np.arange(size), train_size, replace=False)\n",
        "  test_ids = np.setdiff1d(np.arange(size), train_ids)\n",
        "\n",
        "  return train_ids, test_ids\n",
        "\n",
        "train_ids, test_ids = get_split(sample_interactions)\n",
        "\n",
        "def write_file(dataset, ids, filename):\n",
        "  '''\n",
        "  Write processed data to tsv\n",
        "  '''\n",
        "  session_counter = 0\n",
        "  with open(filename, 'w') as w:\n",
        "    w.write('user_id\\titem_id\\tinteraction_type\\tcreated_at\\tfeatures\\n')\n",
        "    for i in ids:\n",
        "      (user_id, subreddit_id, state_label, timestamp, features) = dataset[i]\n",
        "      w.write(str(int(user_id)))\n",
        "      w.write('\\t')\n",
        "      w.write(str(int(subreddit_id)))\n",
        "      w.write('\\t')\n",
        "      w.write(str(int(state_label)))\n",
        "      w.write('\\t')\n",
        "      w.write(str(int(timestamp)))\n",
        "      w.write('\\t')\n",
        "      w.write(str(features))\n",
        "      w.write('\\n')\n",
        "\n",
        "      session_counter += 1\n",
        "\n",
        "    print(f'There are {session_counter} sessions.')\n",
        "\n",
        "write_file(sample_interactions, train_ids, f'train_interactions_embed.tsv')\n",
        "write_file(sample_interactions, test_ids, f'test_interactions_embed.tsv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7_Zpradpg2A",
        "outputId": "4a43c7ec-1048-420c-b16d-327e148d55c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 537958 sessions.\n",
            "There are 134489 sessions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z2n1K9Bna4-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}